{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/papajo/2015/blob/master/Custom_Component.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add a Custom Component\n",
        "We offer support on adding your own components apart from the supported ones (generation, fusion, ranking, etc). This allows for you to add your own custom components\n",
        "\n",
        "Here you will see how to create a component, add it to your configs, and add it to Archon with add_component.\n",
        "\n",
        "Furthermore, you can pass a custom state between components, allowing you to have multiple custom components that can send information between eachother.\n",
        "\n",
        "Alternatively, you can also edit the codebase and add it as a component to `archon/components/`. If doing this route, make sure to also add your component to `__init__.py` within the above directory so it can be imported.\n",
        "\n"
      ],
      "metadata": {
        "id": "CafJeH6XMZ8o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjlt1Vf32844",
        "outputId": "973f4650-8483-41a1-c22b-4ba1989cf7d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/891.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m890.9/891.9 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.9/891.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/160.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/760.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.0/760.0 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install archon-ai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from archon.completions import Archon # 'Archon' is the initialization class\n",
        "from archon.completions.components import Component, Generator #\n",
        "\n",
        "import os\n",
        "os.environ['TOGETHER_API_KEY'] = \"<your-together-key-here\""
      ],
      "metadata": {
        "id": "GIgOWiLo3PgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Component superclass requires you to have __init__ and generate to\n",
        "# interact with the Archon architecture.\n",
        "class custom_component(Component):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "        self.model_name = self.config[\"model\"]\n",
        "        self.model_type = self.config[\"model_type\"]\n",
        "        self.temperature = self.config[\"temperature\"]\n",
        "        self.max_tokens = self.config[\"max_tokens\"]\n",
        "        self.samples = self.config[\"samples\"]\n",
        "\n",
        "        # Generator class helps us handle messaging\n",
        "        self.model = Generator(self.config)\n",
        "\n",
        "    def run(self, conversation: list, prev_state, state):\n",
        "        \"\"\"\n",
        "        Run the component and updates the state accordingly.\n",
        "\n",
        "        Args:\n",
        "            conversation (list[dict]): A list of dictionaries representing the conversation with Archon.\n",
        "                Each dictionary contains role and content\n",
        "            prev_state (dict): A dictionary representing the state from the previous layer.\n",
        "            state (dict): A dictionary holding the values that will be updated from the previous layer to be sent to the next layer\n",
        "        \"\"\"\n",
        "\n",
        "        candidates = prev_state[\"candidates\"]\n",
        "\n",
        "        fused_generations = self.fuse_singer(conversation, candidates)\n",
        "\n",
        "        state[\"candidates\"].extend(fused_generations)\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "\n",
        "    def fuse_singer(self, conversation: list, candidates: list):\n",
        "\n",
        "        # For this example, our component will fuse and turn the output into a song\n",
        "        query = conversation[-1][\"content\"]\n",
        "\n",
        "        prompt = f\"You have been provided with a set of responses from various models to the this query: {query}. \\\n",
        "            Your task is to synthesize these responses into a memerable song that best answers the query\"\n",
        "        for i, reference in enumerate(candidates):\n",
        "            prompt += f\"\\n{i+1}. {reference}\"\n",
        "\n",
        "        messages = (\n",
        "            [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are a helpful assistant who fuses answers and turns them into songs\",\n",
        "                }\n",
        "            ]  # system\n",
        "            + [\n",
        "                message for message in conversation[:-1] if message[\"role\"] != \"system\"\n",
        "            ]  # rest of conversation without query\n",
        "            + [{\"role\": \"user\", \"content\": prompt}]  # prompt\n",
        "        )\n",
        "\n",
        "        fuser_generations = []\n",
        "        for _ in range(self.samples):\n",
        "            output = self.model.generate_from_messages(\n",
        "                messages, temperature=self.temperature\n",
        "            )\n",
        "            if output is not None:\n",
        "                fuser_generations.extend(output)\n",
        "\n",
        "        return fuser_generations\n"
      ],
      "metadata": {
        "id": "ZxNqWEbg5lMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that you've made your component, you can add it to your config\n",
        "archon_config = {\n",
        "    \"name\": \"archon-testing\",\n",
        "    \"custom\": True,  # SET THE CONFIG TO USE CUSTOM\n",
        "    \"layers\": [\n",
        "        [\n",
        "            {\n",
        "                \"type\": \"generator\",\n",
        "                \"model\": \"Qwen/Qwen2-72B-Instruct\",\n",
        "                \"model_type\": \"Together_API\",\n",
        "                \"temperature\": 0.7,\n",
        "                \"max_tokens\": 2048,\n",
        "                \"samples\": 1,\n",
        "            }\n",
        "        ],\n",
        "        [\n",
        "            {\n",
        "                \"type\": \"custom_singer\",  # custom type here\n",
        "                \"model\": \"Qwen/Qwen2-72B-Instruct\",\n",
        "                \"model_type\": \"Together_API\",\n",
        "                \"temperature\": 0.7,\n",
        "                \"max_tokens\": 2048,\n",
        "                \"samples\": 1,\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "}"
      ],
      "metadata": {
        "id": "rTLb7qIXAhw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with custom config\n",
        "archon = Archon(archon_config)\n",
        "\n",
        "# Add component to Archon\n",
        "# name has to match config\n",
        "archon.add_component(\"custom_singer\", custom_component)\n",
        "\n",
        "# Have to manually initialize\n",
        "archon.initialize()\n",
        "\n",
        "# make conversation\n",
        "testing_instruction = [{\"role\": \"user\", \"content\": \"How do I make a cake?\"}]\n",
        "\n",
        "response = archon.generate(testing_instruction)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "3aoi3p8BDg9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99fa37e0-511d-4b0a-8f3f-47b094fff460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2024-10-22 04:41:06.297\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36marchon.completions.archon\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m151\u001b[0m - \u001b[33m\u001b[1mCustom model, make sure to add custom components before initializing.\u001b[0m\n",
            "\u001b[32m2024-10-22 04:41:06.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36marchon.completions.archon\u001b[0m:\u001b[36minitialize_layer\u001b[0m:\u001b[36m79\u001b[0m - \u001b[1mInitialized layer with 1 components\u001b[0m\n",
            "\u001b[32m2024-10-22 04:41:06.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36marchon.completions.archon\u001b[0m:\u001b[36minitialize_layer\u001b[0m:\u001b[36m79\u001b[0m - \u001b[1mInitialized layer with 1 components\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized: Qwen/Qwen2-72B-Instruct\n",
            "Model initialized: Qwen/Qwen2-72B-Instruct\n",
            "Archon initialized with 2 layers.\n",
            "(Verse 1)\n",
            "Gonna make a cake, it's gonna be divine,\n",
            "Measure out your flour, 2 cups just right,\n",
            "Baking powder 2 teaspoons, pinch of salt so fine,\n",
            "Set them all aside, in a bowl they’ll align.\n",
            "\n",
            "(Chorus)\n",
            "Cream the butter, add the sugar, mix it high and low,\n",
            "Eggs one by one, vanilla too, let the cake batter flow,\n",
            "Alternate flour and milk, don’t overmix, you know,\n",
            "Pour and smooth it out, to the oven let it go.\n",
            "\n",
            "(Verse 2)\n",
            "Preheat that oven, to 350 degrees,\n",
            "Prepare your pans, grease and line with ease,\n",
            "Two 9-inch rounds, ready for the feast,\n",
            "Parchment paper’s key, for cakes that won’t cease.\n",
            "\n",
            "(Chorus)\n",
            "Cream the butter, add the sugar, mix it high and low,\n",
            "Eggs one by one, vanilla too, let the cake batter flow,\n",
            "Alternate flour and milk, don’t overmix, you know,\n",
            "Pour and smooth it out, to the oven let it go.\n",
            "\n",
            "(Bridge)\n",
            "Room temp eggs and milk, butter too,\n",
            "For a blend so smooth, your cake will woo,\n",
            "Cool the cakes, don’t rush, frost when through,\n",
            "Decorate your dream cake, as you dream to do.\n",
            "\n",
            "(Outro)\n",
            "Bake for 25 to 30, toothpick as your guide,\n",
            "Cool in the pan, then on a rack, take pride,\n",
            "In the masterpiece, your hands have created with stride,\n",
            "Enjoy your homemade cake, with flavors you can ride.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QPRV76uff5iB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}